\documentclass[11pt]{article}

%%%%%%%% start of generic header CCM 2010-04-09
%% packages
\usepackage{epsfig}
\usepackage{latexsym}
\usepackage{url}
\usepackage{float}
\usepackage[hypertexnames=false,hyperfootnotes=false]{hyperref}
\usepackage{texnansi}
\usepackage{color}
\usepackage{tikz}
\usepackage{subfigure}
\usepackage{afterpage}
\usepackage{enumitem}
\usepackage[boxed]{algorithm}
\usepackage{algpseudocode}
\usepackage[normalem]{ulem}
\usepackage{lmodern}
\usepackage{booktabs}
\usepackage{sectsty}
\usepackage{ifthen}
\usepackage[leqno]{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
%\usepackage{xspace}
\usepackage[margin=10pt,font=small,labelfont=bf]{caption}
%\usepackage[sort&compress]{natbib}
\usepackage{natbib}
%\usepackage{xfrac}
%% useful math macros
\newcommand{\field}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\N}{\ensuremath{\field{N}}} % natural numbers
\newcommand{\R}{\ensuremath{\field{R}}} % real numbers
\newcommand{\Rp}{\ensuremath{\R_+}} % positive real numbers
\newcommand{\Z}{\ensuremath{\field{Z}}} % integers
\newcommand{\Zp}{\ensuremath{\Z_+}} % positive integers
\newcommand{\1}{\ensuremath{\mathbf{1}}} % vector of all 1's
\newcommand{\I}[1]{\ensuremath{\mathbb{I}_{\left\{#1\right\}}}} % indicator function
\newcommand{\Inb}[1]{\ensuremath{\mathbb{I}_{#1}}} % indicator function, no brackets
\newcommand{\tends}{\ensuremath{\rightarrow}} % arrow for limits
\newcommand{\ra}{\ensuremath{\rightarrow<}} % abbreviation for right arrow
\newcommand{\PR}{\ensuremath{\mathsf{P}}} % probability
\newcommand{\E}{\ensuremath{\mathsf{E}}} % expectation
\newcommand{\defeq}{\ensuremath{\triangleq}}
\newcommand{\subjectto}{\text{\rm subject to}} % subject to
\renewcommand{\Re}{\ensuremath{\R}} % expectation
%% some caligraphic symbols
\newcommand{\Ascr}{\ensuremath{\mathcal A}}
\newcommand{\Bscr}{\ensuremath{\mathcal B}}
\newcommand{\Cscr}{\ensuremath{\mathcal C}}
\newcommand{\Dscr}{\ensuremath{\mathcal D}}
\newcommand{\Escr}{\ensuremath{\mathcal E}}
\newcommand{\Fscr}{\ensuremath{\mathcal F}}
\newcommand{\Gscr}{\ensuremath{\mathcal G}}
\newcommand{\Hscr}{\ensuremath{\mathcal H}}
\newcommand{\Iscr}{\ensuremath{\mathcal I}}
\newcommand{\Jscr}{\ensuremath{\mathcal J}}
\newcommand{\Kscr}{\ensuremath{\mathcal K}}
\newcommand{\Lscr}{\ensuremath{\mathcal L}}
\newcommand{\Mscr}{\ensuremath{\mathcal M}}
\newcommand{\Nscr}{\ensuremath{\mathcal N}}
\newcommand{\Oscr}{\ensuremath{\mathcal O}}
\newcommand{\Pscr}{\ensuremath{\mathcal P}}
\newcommand{\Qscr}{\ensuremath{\mathcal Q}}
\newcommand{\Rscr}{\ensuremath{\mathcal R}}
\newcommand{\Sscr}{\ensuremath{\mathcal S}}
\newcommand{\Tscr}{\ensuremath{\mathcal T}}
\newcommand{\Uscr}{\ensuremath{\mathcal U}}
\newcommand{\Vscr}{\ensuremath{\mathcal V}}
\newcommand{\Wscr}{\ensuremath{\mathcal W}}
\newcommand{\Xscr}{\ensuremath{\mathcal X}}
\newcommand{\Yscr}{\ensuremath{\mathcal Y}}
\newcommand{\Zscr}{\ensuremath{\mathcal Z}}
%% math operators
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\interior}{int}
\DeclareMathOperator*{\argmin}{\mathrm{argmin}}
\DeclareMathOperator*{\argmax}{\mathrm{argmax}}
\newcommand{\minimize}{\ensuremath{\mathop{\mathrm{minimize}}\limits}}
\newcommand{\maximize}{\ensuremath{\mathop{\mathrm{maximize}}\limits}}
%% theorem environments
\newtheoremstyle{thm-sf}{}{}{\itshape}{}{\sffamily\bfseries}{.}{ }{}
\theoremstyle{thm-sf}
\newtheorem{remark}{Remark}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{fact}{Fact}
\newtheorem{proposition}{Proposition}
\renewcommand{\qedsymbol}{\ensuremath{\blacksquare}}
\renewcommand{\proofname}{{\normalfont\sffamily\bfseries Proof}}
\newcommand{\proofnamest}[1]{{\normalfont\sffamily\bfseries #1}}
%% Tikz customizations
\usetikzlibrary{arrows,patterns,plotmarks}
\tikzstyle{every picture} += [>=stealth]
%% customize section titles
\allsectionsfont{\sffamily}
\makeatletter
\def\@seccntformat#1{\csname the#1\endcsname.\quad}
\makeatother
%% abstract, table, figure names
\renewcommand{\figurename}{\normalfont\sffamily\bfseries Figure}
\renewcommand{\tablename}{\normalfont\sffamily\bfseries Table}
\renewcommand{\abstractname}{\normalfont\sffamily\bfseries Abstract}
\floatname{algorithm}{\normalfont\sffamily\bfseries Algorithm}
%% other customizations
%\numberwithin{equation}{section}
\floatstyle{ruled}
\newcommand{\emailhref}[1]{\href{mailto:#1}{\tt #1}} % hyperlinked email address
%% boolean for fast compilation
\provideboolean{fastcompile}
\newcommand{\hidefastcompile}[1]{\ifthenelse{\boolean{fastcompile}}{}{#1}}
%% for editing comments
\newcommand{\todo}[1]{{\color{red} \noindent {\sffamily\bfseries TODO:} #1}}
\newcommand{\vff}[1]{{\color{red} \noindent {\sffamily\bfseries VFF:} #1}}
%%%%%%%% end of generic header

%% many person editing commands
\newcommand{\delvf}[1]{{\color{blue} [{\sffamily\bfseries DELETED VF:} #1]}}
\newcommand{\delccm}[1]{{\color{red} [{\sffamily\bfseries DELETED RM:} #1]}}
\newcommand{\notevf}[1]{{\color{blue} [{\sffamily\bfseries NOTE VF:} {\em #1}]}}
\newcommand{\noteccm}[1]{{\color{red} [{\sffamily\bfseries NOTE RM:} {\em #1}]}}
\newcommand{\newvf}[1]{{\color{blue} #1}}
\newcommand{\newccm}[1]{{\color{red} #1}}
\newcommand{\newtw}[1]{{\color{green} #1}}
\newcommand{\newbvr}[1]{{\color{orange} #1}}

%%% margins
\marginparwidth 0pt\marginparsep 0pt
\topskip 0pt\headsep 0pt\headheight 0pt
\oddsidemargin 0pt\evensidemargin 0pt
\textwidth 6.5in \topmargin 0pt\textheight 9.0in
\usepackage{setspace}
\setstretch{1.1}

%%% bibliography
%\setcitestyle{numbers,square}

%\setenumerate[1]{resume}

\begin{document}
	\begin{center} {\Large {\sffamily\bfseries Responses to the Comments Made by \\
				the Editors and the Referees}}
	\end{center}
	
	\bigskip
	
	\section{Response to the Department Editor}
	
	
	
	\section{Response to the Associate Editor}
	
	\subsection{Responses to Comments}
	{\it The two referees from the first round have again provided reports on the paper, and I thank them again. Referee 1 (“I thank the authors...”) has a few minor suggestions (in particular, Referee 1 questions the value of Proposition 1) and recommends a minor revision. Referee 2 (“In my previous review...”) also raises some minor issues (primarily, requesting additional clarity on Lemma 1) and recommends accept.
		I read the authors’ response and the revision again. Like the referees, I appreciate the authors’ efforts and I am almost ready to sign off on the paper. I agree with the referees’ comments and have a few (minor) comments of my own.:
	} 
\newline
\newline
Thank you for your comments. We have ...

	
	\begin{enumerate}
		
		\item {\it I appreciate the authors’ addressing my question on how the OGI($\infty$) values (i.e., the “exact” Gittins indices) are calculated (or approximated), but I am afraid I am still not entirely clear on what was done in the numerical experiments. For the Gaussian case, my understanding is the approximation based on Powell and Ryzhov (2012) is used. I am not sure what was done in the Bernoulli case. The overview at the start of Section 5 (p. 17) also mentions Powell and Ryzhov (2012) but evidently the OGI($\infty$) case is not an approximation in the Bernoulli case (e.g., looking at Tables 7 and 8 in the appendix, it appears these are nearly “exact” calculations).
			
		The response letter does not fully resolve this for me – there you also mention the Brezzi and Lai (2002) paper but I don’t see this mentioned in Section 5. My specific questions are: (a) what methods are used for calculating the “exact” Gittins indices in the Beta-Bernoulli case and (b) when approximations are used (e.g., Powell and Ryzhov 2012) can you please briefly discuss how good these approximations are?
		Apologies if I am missing something here – this does seem important, since a major advantage of the OGI(K) framework is computational tractability.
		}

To answer your specific questions: 

{\em (a) what methods are used for calculating the “exact” Gittins indices in the Beta-Bernoulli case?} To approximate the exact Gittins indices in the Beta-Bernoulli case (such as those reported in Tables 7 and 8), we use value iteration, with a termination condition based on Proposition 2.2.1 of \cite{bertsekas2011dynamic}. That is, we iterate the value iteration operator $k$ times so that $\bar{c}_k - \underline{c}_k$ (as in Proposition 2.2.1) is at most some predetermined fixed tolerance ($0.5 \times 10^{-3}$). In the Beta-Bernoulli case, this effectively requires tracking value at a number of states that grows quadratically in $k$. In our experiments, this typically required on the order of $1/1-\gamma$ iterations when the discount factor was $\gamma$. We earlier referred to this as simply the `naive implementation' in our response, but we make all of this clear in the paper now; apologies for any lack of clarity. 

%As you note, we calculate exact Gittins indices (accurate to the third decimal place - i.e. an additive error of $0.5*10^{-3}$) in Tables 7 and 8 in the Beta-Bernoulli case. This is for purposes of comparison with the $OGI(K)$ indices for the Beta-Bernoulli case which are calculated exactly. To calculate those indices, we use value iteration, with a termination condition based on Proposition 2.2.1 of \cite{.} (in the case of Tables 7 and 8, so that $\bar{c}_k - \underline{c}_k$ (as in that Proposition 2.2.1) is at most $0.5*10^{-3}$). We note that we only need to track value at a number of states that grows quadratically with the number of iterations of value iteration used. We make all of this clear in the paper now; apologies for any lack of clarity. 

{\em (b) when approximations are used (e.g., Powell and Ryzhov 2012) can you please briefly discuss how good these approximations are?}

Thank you for the suggestion. We added a brief discussion of the approximations and believe it helps add context to make the relevant sections more readable.
		
\item {\it Conceptual clarification: the idea behind the choice of the discount factors is as a handle for controlling exploration vs. exploitation. However, given that OGI is based on a finite-horizon approximation, I wonder if this could also be accomplished by tuning the time horizon as well ($K$). In other words, at least from a purely theoretical/conceptual standpoint, is there some redundancy by having both K and $\gamma$ in the OGI calculations? I wonder if similar regret-optimal results could be obtained by taking $\gamma=1$ throughout and increasing K appropriately (and indeed the motivation from the “doubling trick” on p. 11 only involves intuition over a finite horizon).

Of course, there are clear advantages to having both – e.g., in the limit as K grows large, for fixed $\gamma$, we recover the traditional Gittins index. And computationally it’s nice to be able to retain a fixed effort through K while changing $\gamma$.
To be clear, I am not asking the authors to change anything. I just think a brief discussion on this point could potentially help add intuition for the OGI approach.	
}

	
This is a great question. Indeed if we were to calculate exact Gittins indices, then (using the equivalence between discounted infinite horizon problems, and random finite horizon problems) one could conceivably posit that solving the Gittins stopping problem with $\gamma = 1$ and $K_t \triangleq 1/1 - \gamma_t$ at the $t$th epoch provides a good approximation to using the corresponding exact Gittins index $v_{\gamma_t}(\cdot)$ \footnote{In fact, such an index precedes Gittins' paper, see \cite{bradt1956sequential}}. We believe that it is conceivable that similar regret guarantees may be derived for such an approach provided $K_t \sim t$. The downside however, as you already observe, is that this approach would be unnecessarily computationally burdensome, especially as $t$ grows. On the other hand we already know that using $K=1$ with the OGI approximation provides optimal regret guarantees (and very good practical performance), so that in essence having two separate parameters allows for a family of approximations that is simultaneously not as computationally burdensome, but still regret optimal. (Given how speculative many of these points are, we have not added this discussion to the paper, but are happy to do so if you find it necessary.) 




		
	\item {\it The discussion in the first paragraph of Section 3.3 could use a bit more precision. First, the Chappelle and Li (2011) paper studies contextual bandits, which is somewhat different than a classical MAB. Second, although I agree that calculating a Gittins index is harder than, say, Thompson sampling, it’s not always the case that the entire state space $\cal{Y}$ is relevant for the Gittins index calculations (only downstream states from an arm’s current state are needed in the Gittins index calculations).}
	
	Fixed. We were referring to situations where the prior on the mean of a single arm is itself specified by a high-dimensional parameter vector, but indeed, this is not as interesting a case practically outside of the contextual bandit setting which we do not address. 
	
	\item {\it A brief discussion of the Beta(1,1) assumption in Theorem 1 would be useful. This is a natural (and somewhat standard) assumption in that it assumes no prior knowledge about arms. But presumably such assumptions are not necessary for obtaining asymptotically optimal regret.
	}

	Agreed. We mentioned in the text that the uniform prior is a natural assumption in these cases.
	
	\item {\it  P. 17, line 45 – there appears to be a typo after “choice of $\alpha$.”}
	
	Fixed.
	
	\item {\it It probably would be helpful to describe the large-scale experiments as Bernoulli bandits earlier in Section 5.2 (the reader does not get to this until the third paragraph).}
	
	Great suggestion. We re-wrote the first few paragraphs of Section 5.2 accordingly.
	\end{enumerate}
	
	\newpage
	\section{Response to  Referee 1}
	
	{\it I thank the authors for their response to my comments. As I said in the previous round, the paper makes a significant contribution to the MAB literature. I only have one last comment (see below). Congratulations on your excellent work.
		I'm not convinced about the value of Proposition 1 and the discussion about Bayes risk. It's interesting as a curiosity, but having it in section 3.2 is more of a distraction/detour that confuses the reader rather than something that helps building intuition. The index in Proposition 1 is not exactly the OGI analyzed later and the authors acknowledge in the response that this result is "not essential to the main results of the paper in any way". Therefore, it can be moved to the appendix. The paper can mention that the OGI policy is motivated by the Bayesian setting, and though the paper cannot show that it's optimal in the Bayesian regret sense, it does surprisingly achieve optimal regret in the frequentist sense. The reader that's interested in Bayesian regret can be referred to the appendix for further discussion. A streamlined paper along these lines will gain in readability.
		
Note also that the current section 3.2 needs some editing. The three lines preceding Proposition 1 (starting with "and consider using the policy...") appear twice and the factor with respect to the optimal Bayes risk is now $\log^2 T$ (it still says $\log T$ from the previous version).	
}
\newline
\newline
\noindent
Thank you for your assessment of the contribution! We fixed the typos you point out. We also edited that section to alert the reader to the portion of the section that they could skip without loss of continuity. After struggling with various iterations, we eventually chose to keep the statement of the proposition in the body, since we find that it really helps solidify intuition for the discount factor schedule in the OGI scheme we propose. While you are indeed correct that the proposition itself is not essential to proving our main theorem, absent the proposition, the discount factor schedule we propose would not be nearly as well motivated and our attempts to say this in words felt quite imprecise. Finally, it is worth noting that the other reviewer (who studied various aspects of the result carefully) and the AE (who asks about other approximation schemes motivated by the section) evidently found this content valuable. 
	
	\newpage
	\section{Response to Referee 2}
	{
	\it 
	In my previous review, I made several suggestions to the authors and stated that my main concern was a few technical issues in the proofs. Based on the new proofs, it seems the technical issues have been fixed. Thanks to the authors for a clear and thorough revision.
	}
    \newline
    \newline
    Thank you for all your feedback. We were able to greatly improve and fix the technical issues in our paper because of it. We responded to your most recent comments below.
	\subsection{Typos or minor issues}
	
	\begin{itemize}
		\item {\it On Lemma 1: It would be helpful if you stated this more clearly. Now that you revised the statement to be ``frequentest", the proof you wrote actually constructs jointly a prior and problem instance on which regret grows linearly. I don't think it's sufficiently clear to say ``there exists an instance of the multi-armed bandit problem, with parameters $\theta$" since this does not clarify that you’ve picked a prior that fails on this instance. Less important, but it also feels like you can substantially simplify the proof of Lemma 1: can’t you just pick $(\alpha + 1, \alpha)$ to be the prior parameters of the second arm rather than create a construction in which that arm is sampled exactly once?
		}
		
		These are great points -- thank you. We re-worded the Lemma to say that there exists an instance of the multi-armed bandit problem with a certain prior, and a $\theta$ drawn from the prior, in which regret grows linearly. We believe this is indeed clearer.
		
		We also simplified the proof as you suggested.
		
		\item {\it On Proposition 1: Looks correct. I find the proof approach using Lemma 6 to be pretty elegant.
			\begin{itemize}
				\item Typo: `that specifics a choice of arm for every epoch'
				\item  Typo: should say $\lim_{T\to\infty}$ not $\lim T$.
			\end{itemize}
		}
	
		Fixed both.
	
		\item {\it Lemma 7: At the start of the proof, I think you want to assume $X_{i,t}$ is not almost surely equal to$ B$, or else you should write weak rather than strict inequalities at the start of the proof.}
		Thank you, this is a great observation. We stated this assumption now in Lemma 7.
	%% BEGIN RESPONSE %%
	
	
	
	%% END RESPONSE %%


	
	\end{itemize}

	

%\singlespacing



\bibliographystyle{named}
\bibliography{references} 
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
